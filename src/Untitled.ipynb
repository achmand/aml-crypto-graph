{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import cryptoaml.datareader as cdr\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>visibility</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_sustained_wind_speed</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>ts</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1006.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>30.1</td>\n",
       "      <td>39.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1015.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9224</th>\n",
       "      <td>3.3</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>16.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>15.3</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9226</th>\n",
       "      <td>9.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1022.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9227</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>1035.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>1034.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>424</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9229 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  dew_point  sea_level_pressure  visibility  avg_wind_speed  \\\n",
       "0            26.8       22.2              1006.2         8.1            10.9   \n",
       "1            34.6       32.9              1004.6         3.9            13.8   \n",
       "2            26.4       21.5              1006.9         8.0            18.7   \n",
       "3            14.7        7.9              1009.9         8.1            14.1   \n",
       "4            30.6       22.7              1015.1        12.6             9.3   \n",
       "...           ...        ...                 ...         ...             ...   \n",
       "9224          3.3       -7.3              1023.5        19.3             2.5   \n",
       "9225         16.5       12.2              1015.7        11.7             2.7   \n",
       "9226          9.6        2.4              1022.3        12.6            12.4   \n",
       "9227          0.5       -9.6              1035.8        20.1             6.9   \n",
       "9228          3.0       -6.9              1034.2        19.9             4.1   \n",
       "\n",
       "      max_sustained_wind_speed  max_temperature  min_temperature   ts   ts  \n",
       "0                         19.0             34.0             21.0    1    1  \n",
       "1                         22.0             36.0             33.1    1    1  \n",
       "2                         30.1             39.9             16.0    1    1  \n",
       "3                         22.0             21.0              9.0    1    1  \n",
       "4                         17.1             42.1             19.0    1    1  \n",
       "...                        ...              ...              ...  ...  ...  \n",
       "9224                       5.8             14.2             -3.8  424  424  \n",
       "9225                       8.0             17.2             15.3  424  424  \n",
       "9226                      22.0             15.3              4.1  424  424  \n",
       "9227                      11.8              6.3             -3.8  424  424  \n",
       "9228                      14.0             18.1             -4.9  424  424  \n",
       "\n",
       "[9229 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>visibility</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_sustained_wind_speed</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>ts</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>20.9</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1025.3</td>\n",
       "      <td>18.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>15.3</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>25.5</td>\n",
       "      <td>23.2</td>\n",
       "      <td>1029.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>20.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1032.8</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>22.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1023.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9233</th>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1018.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14663</th>\n",
       "      <td>32.6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1022.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14664</th>\n",
       "      <td>36.8</td>\n",
       "      <td>25.4</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14665</th>\n",
       "      <td>41.9</td>\n",
       "      <td>29.9</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>62.6</td>\n",
       "      <td>28.4</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14666</th>\n",
       "      <td>42.4</td>\n",
       "      <td>29.7</td>\n",
       "      <td>1011.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>51.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>36.6</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5439 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  dew_point  sea_level_pressure  visibility  avg_wind_speed  \\\n",
       "9229          20.9       14.4              1025.3        18.2             5.4   \n",
       "9230          25.5       23.2              1029.2         5.2             1.6   \n",
       "9231          20.7       18.9              1032.8        10.3             2.4   \n",
       "9232          22.3       18.7              1023.9        11.8             2.9   \n",
       "9233          31.0       28.0              1018.8        14.7             3.0   \n",
       "...            ...        ...                 ...         ...             ...   \n",
       "14663         32.6       21.9              1022.7         7.0            12.4   \n",
       "14664         36.8       25.4              1014.9         7.0            10.0   \n",
       "14665         41.9       29.9              1010.0         7.0             4.7   \n",
       "14666         42.4       29.7              1011.3         7.0             3.3   \n",
       "14667         36.6       29.5              1017.9         6.8             4.8   \n",
       "\n",
       "       max_sustained_wind_speed  max_temperature  min_temperature   ts   ts  \n",
       "9229                        9.9             25.2             15.3  425  425  \n",
       "9230                        4.9             29.1             23.2  425  425  \n",
       "9231                        7.0             27.1             14.2  425  425  \n",
       "9232                        8.9             33.1             13.1  425  425  \n",
       "9233                        9.9             36.0             26.2  425  425  \n",
       "...                         ...              ...              ...  ...  ...  \n",
       "14663                      26.0             41.0             24.8  606  606  \n",
       "14664                      19.0             57.2             21.2  606  606  \n",
       "14665                       9.9             62.6             28.4  606  606  \n",
       "14666                       8.9             51.8             32.0  606  606  \n",
       "14667                      13.0             53.6             24.8  606  606  \n",
       "\n",
       "[5439 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noaa = cdr.get_data(\"noaa_weather\", config_file=\"configuration/data/ell_data_config_ncr.yaml\")\n",
    "dataset = noaa.train_test_split(train_size=0.7)[\"ALL\"]\n",
    "\n",
    "train_X = dataset.train_X\n",
    "train_y = dataset.train_y\n",
    "test_X = dataset.test_X\n",
    "\n",
    "\n",
    "display(train_X)\n",
    "\n",
    "display(test_X)\n",
    "\n",
    "\n",
    "# # display(train_X)\n",
    "\n",
    "# counter = Counter(train_y)\n",
    "# print(\"Train set counter [Label]: {}\".format(counter))\n",
    "# _, y = ncr.fit_resample(train_X, train_y)\n",
    "\n",
    "# # display(data[\"ALL\"].train_X.shape)\n",
    "# # display(data[\"ALL\"].test_X.shape)\n",
    "\n",
    "# counter = Counter(y)\n",
    "# print(\"Train set counter after NCL [Label]: {}\".format(counter))\n",
    "\n",
    "# indices = ncr.sample_indices_\n",
    "# samples_kept_X = train_X.iloc[indices]\n",
    "# samples_kept_y = train_y.iloc[indices]\n",
    "# undersampled_set_X = samples_kept_X.append(test_X, ignore_index=True)\n",
    "# undersampled_set_y = samples_kept_y.append(dataset.test_y, ignore_index=True)\n",
    "\n",
    "# undersampled_set_X.to_csv(\"ncl_noaa_data.csv\", index=False, header=False)\n",
    "# undersampled_set_y.to_csv(\"ncl_noaa_class.csv\", index=False, header=False)\n",
    "\n",
    "\n",
    "# undersampled_set.drop(elliptic_data.feature_cols_NE_, inplace=True, axis=1)\n",
    "\n",
    "# display(undersampled_set)\n",
    "# display(undersampled_set_y)\n",
    "\n",
    "# train_data = data.train_X\n",
    "\n",
    "# display(train_data)\n",
    "# train_data[\"class\"] = data.train_y\n",
    "# test_data = data.test_X\n",
    "# test_data[\"class\"] = data.test_y \n",
    "# # data = train_data.append(test_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# from skmultiflow.core.base import BaseSKMObject, ClassifierMixin\n",
    "# from skmultiflow.drift_detection import ADWIN\n",
    "# from skmultiflow.utils import get_dimensions\n",
    "\n",
    "\n",
    "# class AdaptiveXGBoostClassifier(BaseSKMObject, ClassifierMixin):\n",
    "#     _PUSH_STRATEGY = 'push'\n",
    "#     _REPLACE_STRATEGY = 'replace'\n",
    "#     _UPDATE_STRATEGIES = [_PUSH_STRATEGY, _REPLACE_STRATEGY]\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  n_estimators=30,\n",
    "#                  learning_rate=0.3,\n",
    "#                  max_depth=6,\n",
    "#                  max_window_size=1000,\n",
    "#                  min_window_size=None,\n",
    "#                  detect_drift=False,\n",
    "#                  update_strategy='replace'):\n",
    "#         \"\"\"\n",
    "#         Adaptive XGBoost classifier.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         n_estimators: int (default=5)\n",
    "#             The number of estimators in the ensemble.\n",
    "\n",
    "#         learning_rate:\n",
    "#             Learning rate, a.k.a eta.\n",
    "\n",
    "#         max_depth: int (default = 6)\n",
    "#             Max tree depth.\n",
    "\n",
    "#         max_window_size: int (default=1000)\n",
    "#             Max window size.\n",
    "\n",
    "#         min_window_size: int (default=None)\n",
    "#             Min window size. If this parameters is not set, then a fixed size\n",
    "#             window of size ``max_window_size`` will be used.\n",
    "\n",
    "#         detect_drift: bool (default=False)\n",
    "#             If set will use a drift detector (ADWIN).\n",
    "\n",
    "#         update_strategy: str (default='replace')\n",
    "#             | The update strategy to use:\n",
    "#             | 'push' - the ensemble resembles a queue\n",
    "#             | 'replace' - oldest ensemble members are replaced by newer ones\n",
    "\n",
    "#         Notes\n",
    "#         -----\n",
    "#         The Adaptive XGBoost [1]_ (AXGB) classifier is an adaptation of the\n",
    "#         XGBoost algorithm for evolving data streams. AXGB creates new members\n",
    "#         of the ensemble from mini-batches of data as new data becomes\n",
    "#         available.  The maximum ensemble  size is fixed, but learning does not\n",
    "#         stop once this size is reached, the ensemble is updated on new data to\n",
    "#         ensure consistency with the current data distribution.\n",
    "\n",
    "#         References\n",
    "#         ----------\n",
    "#         .. [1] Montiel, Jacob, Mitchell, Rory, Frank, Eibe, Pfahringer,\n",
    "#            Bernhard, Abdessalem, Talel, and Bifet, Albert. “AdaptiveXGBoost for\n",
    "#            Evolving Data Streams”. In:IJCNN’20. International Joint Conference\n",
    "#            on Neural Networks. 2020. Forthcoming.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.n_estimators = n_estimators\n",
    "#         self.max_depth = max_depth\n",
    "#         self.max_window_size = max_window_size\n",
    "#         self.min_window_size = min_window_size\n",
    "#         self._first_run = True\n",
    "#         self._ensemble = None\n",
    "#         self.detect_drift = detect_drift\n",
    "#         self._drift_detector = None\n",
    "#         self._X_buffer = np.array([])\n",
    "#         self._y_buffer = np.array([])\n",
    "#         self._samples_seen = 0\n",
    "#         self._model_idx = 0\n",
    "#         if update_strategy not in self._UPDATE_STRATEGIES:\n",
    "#             raise AttributeError(\"Invalid update_strategy: {}\\n\"\n",
    "#                                  \"Valid options: {}\".format(update_strategy,\n",
    "#                                                             self._UPDATE_STRATEGIES))\n",
    "#         self.update_strategy = update_strategy\n",
    "#         self._configure()\n",
    "\n",
    "#     def _configure(self):\n",
    "#         if self.update_strategy == self._PUSH_STRATEGY:\n",
    "#             self._ensemble = []\n",
    "#         elif self.update_strategy == self._REPLACE_STRATEGY:\n",
    "#             self._ensemble = [None] * self.n_estimators\n",
    "#         self._reset_window_size()\n",
    "#         self._init_margin = 0.0\n",
    "#         self._boosting_params = {\"silent\": True,\n",
    "#                                  \"objective\": \"binary:logistic\",\n",
    "#                                  \"eta\": self.learning_rate,\n",
    "#                                  \"max_depth\": self.max_depth}\n",
    "#         if self.detect_drift:\n",
    "#             self._drift_detector = ADWIN()\n",
    "\n",
    "#     def reset(self):\n",
    "#         \"\"\"\n",
    "#         Reset the estimator.\n",
    "#         \"\"\"\n",
    "#         self._first_run = True\n",
    "#         self._configure()\n",
    "\n",
    "#     def partial_fit(self, X, y, classes=None, sample_weight=None):\n",
    "#         \"\"\"\n",
    "#         Partially (incrementally) fit the model.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X: numpy.ndarray\n",
    "#             An array of shape (n_samples, n_features) with the data upon which\n",
    "#             the algorithm will create its model.\n",
    "\n",
    "#         y: Array-like\n",
    "#             An array of shape (, n_samples) containing the classification\n",
    "#             targets for all samples in X. Only binary data is supported.\n",
    "\n",
    "#         classes: Not used.\n",
    "\n",
    "#         sample_weight: Not used.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         AdaptiveXGBoostClassifier\n",
    "#             self\n",
    "#         \"\"\"\n",
    "#         for i in range(X.shape[0]):\n",
    "#             self._partial_fit(np.array([X[i, :]]), np.array([y[i]]))\n",
    "#         return self\n",
    "\n",
    "#     def _partial_fit(self, X, y):\n",
    "#         if self._first_run:\n",
    "#             self._X_buffer = np.array([]).reshape(0, get_dimensions(X)[1])\n",
    "#             self._y_buffer = np.array([])\n",
    "#             self._first_run = False\n",
    "#         self._X_buffer = np.concatenate((self._X_buffer, X))\n",
    "#         self._y_buffer = np.concatenate((self._y_buffer, y))\n",
    "#         while self._X_buffer.shape[0] >= self.window_size:\n",
    "#             self._train_on_mini_batch(X=self._X_buffer[0:self.window_size, :],\n",
    "#                                       y=self._y_buffer[0:self.window_size])\n",
    "#             delete_idx = [i for i in range(self.window_size)]\n",
    "#             self._X_buffer = np.delete(self._X_buffer, delete_idx, axis=0)\n",
    "#             self._y_buffer = np.delete(self._y_buffer, delete_idx, axis=0)\n",
    "\n",
    "#             # Check window size and adjust it if necessary\n",
    "#             self._adjust_window_size()\n",
    "\n",
    "#         # Support for concept drift\n",
    "#         if self.detect_drift:\n",
    "#             correctly_classifies = self.predict(X) == y\n",
    "#             # Check for warning\n",
    "#             self._drift_detector.add_element(int(not correctly_classifies))\n",
    "#             # Check if there was a change\n",
    "#             if self._drift_detector.detected_change():\n",
    "#                 # Reset window size\n",
    "#                 self._reset_window_size()\n",
    "#                 if self.update_strategy == self._REPLACE_STRATEGY:\n",
    "#                     self._model_idx = 0\n",
    "\n",
    "#     def _adjust_window_size(self):\n",
    "#         if self._dynamic_window_size < self.max_window_size:\n",
    "#             self._dynamic_window_size *= 2\n",
    "#             if self._dynamic_window_size > self.max_window_size:\n",
    "#                 self.window_size = self.max_window_size\n",
    "#             else:\n",
    "#                 self.window_size = self._dynamic_window_size\n",
    "\n",
    "#     def _reset_window_size(self):\n",
    "#         if self.min_window_size:\n",
    "#             self._dynamic_window_size = self.min_window_size\n",
    "#         else:\n",
    "#             self._dynamic_window_size = self.max_window_size\n",
    "#         self.window_size = self._dynamic_window_size\n",
    "\n",
    "#     def _train_on_mini_batch(self, X, y):\n",
    "#         if self.update_strategy == self._REPLACE_STRATEGY:\n",
    "#             booster = self._train_booster(X, y, self._model_idx)\n",
    "#             # Update ensemble\n",
    "#             self._ensemble[self._model_idx] = booster\n",
    "#             self._samples_seen += X.shape[0]\n",
    "#             self._update_model_idx()\n",
    "#         else:   # self.update_strategy == self._PUSH_STRATEGY\n",
    "#             booster = self._train_booster(X, y, len(self._ensemble))\n",
    "#             # Update ensemble\n",
    "#             if len(self._ensemble) == self.n_estimators:\n",
    "#                 self._ensemble.pop(0)\n",
    "#             self._ensemble.append(booster)\n",
    "#             self._samples_seen += X.shape[0]\n",
    "\n",
    "#     def _train_booster(self, X: np.ndarray, y: np.ndarray, last_model_idx: int):\n",
    "#         d_mini_batch_train = xgb.DMatrix(X, y.astype(int))\n",
    "#         # Get margins from trees in the ensemble\n",
    "#         margins = np.asarray([self._init_margin] * d_mini_batch_train.num_row())\n",
    "#         for j in range(last_model_idx):\n",
    "#             margins = np.add(margins,\n",
    "#                              self._ensemble[j].predict(d_mini_batch_train, output_margin=True))\n",
    "#         d_mini_batch_train.set_base_margin(margin=margins)\n",
    "#         booster = xgb.train(params=self._boosting_params,\n",
    "#                             dtrain=d_mini_batch_train,\n",
    "#                             num_boost_round=1,\n",
    "#                             verbose_eval=False)\n",
    "#         return booster\n",
    "\n",
    "#     def _update_model_idx(self):\n",
    "#         self._model_idx += 1\n",
    "#         if self._model_idx == self.n_estimators:\n",
    "#             self._model_idx = 0\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         \"\"\"\n",
    "#         Predict the class label for sample X\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X: numpy.ndarray\n",
    "#             An array of shape (n_samples, n_features) with the samples to\n",
    "#             predict the class label for.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         numpy.ndarray\n",
    "#             A 1D array of shape (, n_samples), containing the\n",
    "#             predicted class labels for all instances in X.\n",
    "\n",
    "#         \"\"\"\n",
    "#         if self._ensemble:\n",
    "#             if self.update_strategy == self._REPLACE_STRATEGY:\n",
    "#                 trees_in_ensemble = sum(i is not None for i in self._ensemble)\n",
    "#             else:   # self.update_strategy == self._PUSH_STRATEGY\n",
    "#                 trees_in_ensemble = len(self._ensemble)\n",
    "#             if trees_in_ensemble > 0:\n",
    "#                 d_test = xgb.DMatrix(X)\n",
    "#                 for i in range(trees_in_ensemble - 1):\n",
    "#                     margins = self._ensemble[i].predict(d_test, output_margin=True)\n",
    "#                     d_test.set_base_margin(margin=margins)\n",
    "#                 predicted = self._ensemble[trees_in_ensemble - 1].predict(d_test)\n",
    "#                 return np.array(predicted > 0.5).astype(int)\n",
    "#         # Ensemble is empty, return default values (0)\n",
    "#         return np.zeros(get_dimensions(X)[0])\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         \"\"\"\n",
    "#         Not implemented for this method.\n",
    "#         \"\"\"\n",
    "#         raise NotImplementedError(\"predict_proba is not implemented for this method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skmultiflow.data import ConceptDriftStream\n",
    "# from skmultiflow.evaluation import EvaluatePrequential\n",
    "\n",
    "\n",
    "# # Adaptive XGBoost classifier parameters\n",
    "# n_estimators = 30       # Number of members in the ensemble\n",
    "# learning_rate = 0.3     # Learning rate or eta\n",
    "# max_depth = 6           # Max depth for each tree in the ensemble\n",
    "# max_window_size = 1000  # Max window size\n",
    "# min_window_size = 1     # set to activate the dynamic window strategy\n",
    "# detect_drift = False    # Enable/disable drift detection\n",
    "\n",
    "# AXGBp = AdaptiveXGBoostClassifier(update_strategy='push',\n",
    "#                                   n_estimators=n_estimators,\n",
    "#                                   learning_rate=learning_rate,\n",
    "#                                   max_depth=max_depth,\n",
    "#                                   max_window_size=max_window_size,\n",
    "#                                   min_window_size=min_window_size,\n",
    "#                                   detect_drift=detect_drift)\n",
    "\n",
    "# AXGBr = AdaptiveXGBoostClassifier(update_strategy='replace',\n",
    "#                                   n_estimators=n_estimators,\n",
    "#                                   learning_rate=learning_rate,\n",
    "#                                   max_depth=max_depth,\n",
    "#                                   max_window_size=max_window_size,\n",
    "#                                   min_window_size=min_window_size,\n",
    "#                                   detect_drift=detect_drift)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display(train_data)\n",
    "# # display(test_data)\n",
    "\n",
    "# model = xgb.XGBClassifier()\n",
    "# model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# y_pred = model.predict(test_data.iloc[:,:-1])\n",
    "# ts_f1 = round(f1_score(test_data[\"class\"], y_pred, average='binary'), 3)\n",
    "# print(ts_f1)\n",
    "\n",
    "# true_test = []\n",
    "# f1_scores = []\n",
    "# predictions_test = []\n",
    "# timestep_range = np.arange(35, 50)\n",
    "# for timestep in timestep_range:\n",
    "#     test = test_data[test_data[\"ts\"] == timestep]\n",
    "#     test_X = test.iloc[:,:-1]\n",
    "#     test_y = test[\"class\"]\n",
    "    \n",
    "#     y_pred = model.predict(test_X)\n",
    "#     ts_f1 = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#     print(\"Timestep: {} | F1-Score: {}\".format(timestep, ts_f1))\n",
    "#     f1_scores.append(ts_f1)\n",
    "#     true_test.append(test_y)\n",
    "#     predictions_test.append(y_pred)\n",
    "        \n",
    "# f1_score_test = f1_score(np.concatenate(true_test, axis=0),   \n",
    "#                          np.concatenate(predictions_test, axis=0), \n",
    "#                          average='binary')\n",
    "# print(\"F1-Score on test set: {}\".format(round(f1_score_test, 3)))     \n",
    "\n",
    "# recall_score_test = recall_score(np.concatenate(true_test, axis=0),   \n",
    "#                                  np.concatenate(predictions_test, axis=0), \n",
    "#                                  average='binary')\n",
    "# print(\"Recall on test set: {}\".format(round(recall_score_test, 3)))      \n",
    "\n",
    "# precision_score_test = precision_score(np.concatenate(true_test, axis=0),   \n",
    "#                                        np.concatenate(predictions_test, axis=0), \n",
    "#                                        average='binary')\n",
    "# print(\"Precision on test set: {}\".format(round(precision_score_test, 3)))    \n",
    "\n",
    "# confusion_matrix_test = confusion_matrix(np.concatenate(true_test, axis=0), \n",
    "#                                          np.concatenate(predictions_test, axis=0))\n",
    "# print(\"Confusion_matrix: {}\".format(confusion_matrix_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # display(train_data)\n",
    "# # display(test_data)\n",
    "\n",
    "# # ncr_X, ncr_y = ncr.fit_resample(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "# # sm = SMOTE()\n",
    "# # X, y = sm.fit_resample(ncr_X, ncr_y)\n",
    "\n",
    "# # ncr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "# # ncr_X, ncr_y = ncr.fit_resample(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# model = xgb.XGBClassifier()\n",
    "# model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# # model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# max_timestep = test_data[\"ts\"].max()\n",
    "# true_test = []\n",
    "# predictions_test = []\n",
    "# timestep_range = np.arange(35, max_timestep)\n",
    "\n",
    "# ensembles = []\n",
    "\n",
    "# for timestep in timestep_range:\n",
    "\n",
    "#     train = test_data[test_data[\"ts\"] == timestep]\n",
    "#     train_X = train.iloc[:,:-1]\n",
    "#     train_y = train[\"class\"]\n",
    "    \n",
    "#     if timestep == 35:\n",
    "#         y_pred = model.predict(train_X)\n",
    "#         ts_f1 = round(f1_score(train_y, y_pred, average='binary'), 3)     \n",
    "#         print(\"Timestep: {} | F1-Score: {}\".format(timestep, ts_f1))\n",
    "#         true_test.append(train_y)\n",
    "#         predictions_test.append(y_pred)\n",
    "     \n",
    "#     #ncr_X, ncr_y = ncr.fit_resample(train_X, train_y)\n",
    "#     booster = model.get_booster()\n",
    "#     model.fit(train_X, train_y, xgb_model=booster)\n",
    "       \n",
    "#     test = test_data[test_data[\"ts\"] == timestep + 1]\n",
    "#     test_X = test.iloc[:,:-1]\n",
    "#     test_y = test[\"class\"]\n",
    "    \n",
    "#     y_pred = model.predict(test_X)\n",
    "#     ts_f1 = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#     print(\"Timestep: {} | F1-Score: {}\".format(timestep + 1, ts_f1))\n",
    "#     true_test.append(test_y)\n",
    "#     predictions_test.append(y_pred)\n",
    "        \n",
    "#     tmp_model = xgb.XGBClassifier()\n",
    "#     tmp_model.fit(train_X, train_y)\n",
    "#     ensembles.append(tmp_model) \n",
    "    \n",
    "#     print(\"--------------------\")\n",
    "#     for i in range(len(ensembles) - 1):\n",
    "#         tmp = ensembles[i]\n",
    "#         tmp_booster = tmp.get_booster()\n",
    "#         tmp.fit(train_X, train_y, xgb_model=tmp_booster)\n",
    "#         ensembles[i] = tmp \n",
    "#         y_pred = tmp.predict(test_X)\n",
    "#         f1_tmp = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#         print(f1_tmp)\n",
    "#     print(\"--------------------\")\n",
    "\n",
    "    \n",
    "# #     y_pred = tmp_model.predict(test_X)\n",
    "# #     ts_f1_tmp = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "    \n",
    "# #     if ts_f1_tmp > ts_f1:\n",
    "# #         print(\"TMP_Timestep: {} | F1-Score: {}\".format(timestep + 1, ts_f1_tmp))\n",
    "\n",
    "    \n",
    "    \n",
    "# f1_score_test = f1_score(np.concatenate(true_test, axis=0),   \n",
    "#                          np.concatenate(predictions_test, axis=0), \n",
    "#                          average='binary')\n",
    "# print(\"F1-Score on test set: {}\".format(round(f1_score_test, 3)))     \n",
    "\n",
    "# recall_score_test = recall_score(np.concatenate(true_test, axis=0),   \n",
    "#                                  np.concatenate(predictions_test, axis=0), \n",
    "#                                  average='binary')\n",
    "# print(\"Recall on test set: {}\".format(round(recall_score_test, 3)))      \n",
    "\n",
    "# precision_score_test = precision_score(np.concatenate(true_test, axis=0),   \n",
    "#                                        np.concatenate(predictions_test, axis=0), \n",
    "#                                        average='binary')\n",
    "# print(\"Precision on test set: {}\".format(round(precision_score_test, 3)))    \n",
    "\n",
    "# confusion_matrix_test = confusion_matrix(np.concatenate(true_test, axis=0), \n",
    "#                                          np.concatenate(predictions_test, axis=0))\n",
    "# print(\"Confusion_matrix: {}\".format(confusion_matrix_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('btc-classifier': conda)",
   "language": "python",
   "name": "python37664bitbtcclassifiercondaf328939486114fc0aeb107830f867d66"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
