{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import cryptoaml.datareader as cdr\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12720, 9)\n",
      "(5439, 9)\n"
     ]
    }
   ],
   "source": [
    "# elliptic = cdr.get_data(\"elliptic\")\n",
    "# data = elliptic.train_test_split(train_size=0.7, \n",
    "#                                  feat_set=\"AF\", \n",
    "#                                  inc_meta=False,\n",
    "#                                  inc_unknown=False)\n",
    "\n",
    "# train_data = data.train_X\n",
    "\n",
    "elliptic = cdr.get_data(\"noaa_weather\")\n",
    "data = elliptic.train_test_split(train_size=0.7)[\"ALL\"]\n",
    "\n",
    "\n",
    "# test_data = data.test_X\n",
    "\n",
    "print(data.train_X.shape)\n",
    "\n",
    "print(data.test_X.shape)\n",
    "\n",
    "# print(data.train_y[data.train_X[\"label\"] == 1])\n",
    "# print(data.test_X.shape)\n",
    "\n",
    "\n",
    "# display(data.train_y.iloc[0] == 1)\n",
    "# display(data.test_X)\n",
    "\n",
    "# # print(test_data.shape)\n",
    "\n",
    "# noaa = cdr.get_data(\"noaa_weather\", config_file=\"configuration/data/ell_data_config_ncr.yaml\")\n",
    "# dataset = noaa.train_test_split(train_size=0.7)[\"ALL\"]\n",
    "\n",
    "# # train_X = dataset.train_X\n",
    "# # train_y = dataset.train_y\n",
    "# test_X = dataset.test_X\n",
    "# display(test_X)\n",
    "# test_y = dataset.test_y\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# clf = xgb.XGBClassifier(random_state=58, subsample=0.5)\n",
    "# clf.fit(train_X, train_y)\n",
    "# y_pred = clf.predict(test_X)\n",
    "\n",
    "# EXP_RESULT_PATH         = \"persistence/experiment_2.4/results\"\n",
    "# BENCHMARK_RESULTS       = \"{}/{}\".format(EXP_RESULT_PATH, \"benchmark_model_results.pkl\")\n",
    "# BENCHMARK_TUNED_RESULTS = \"{}/{}\".format(EXP_RESULT_PATH, \"tuned_benchmark_results.pkl\")\n",
    "# DEFAULT_RESULTS         = \"{}/{}\".format(EXP_RESULT_PATH, \"defaults_models_results.pkl\")\n",
    "# TUNED_RESULTS           = \"{}/{}\".format(EXP_RESULT_PATH, \"tuned_models_results.pkl\")\n",
    "\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skmultiflow.data import ConceptDriftStream\n",
    "# from skmultiflow.evaluation import EvaluatePrequential\n",
    "\n",
    "\n",
    "# # Adaptive XGBoost classifier parameters\n",
    "# n_estimators = 30       # Number of members in the ensemble\n",
    "# learning_rate = 0.3     # Learning rate or eta\n",
    "# max_depth = 6           # Max depth for each tree in the ensemble\n",
    "# max_window_size = 1000  # Max window size\n",
    "# min_window_size = 1     # set to activate the dynamic window strategy\n",
    "# detect_drift = False    # Enable/disable drift detection\n",
    "\n",
    "# AXGBp = AdaptiveXGBoostClassifier(update_strategy='push',\n",
    "#                                   n_estimators=n_estimators,\n",
    "#                                   learning_rate=learning_rate,\n",
    "#                                   max_depth=max_depth,\n",
    "#                                   max_window_size=max_window_size,\n",
    "#                                   min_window_size=min_window_size,\n",
    "#                                   detect_drift=detect_drift)\n",
    "\n",
    "# AXGBr = AdaptiveXGBoostClassifier(update_strategy='replace',\n",
    "#                                   n_estimators=n_estimators,\n",
    "#                                   learning_rate=learning_rate,\n",
    "#                                   max_depth=max_depth,\n",
    "#                                   max_window_size=max_window_size,\n",
    "#                                   min_window_size=min_window_size,\n",
    "#                                   detect_drift=detect_drift)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display(train_data)\n",
    "# # display(test_data)\n",
    "\n",
    "# model = xgb.XGBClassifier()\n",
    "# model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# y_pred = model.predict(test_data.iloc[:,:-1])\n",
    "# ts_f1 = round(f1_score(test_data[\"class\"], y_pred, average='binary'), 3)\n",
    "# print(ts_f1)\n",
    "\n",
    "# true_test = []\n",
    "# f1_scores = []\n",
    "# predictions_test = []\n",
    "# timestep_range = np.arange(35, 50)\n",
    "# for timestep in timestep_range:\n",
    "#     test = test_data[test_data[\"ts\"] == timestep]\n",
    "#     test_X = test.iloc[:,:-1]\n",
    "#     test_y = test[\"class\"]\n",
    "    \n",
    "#     y_pred = model.predict(test_X)\n",
    "#     ts_f1 = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#     print(\"Timestep: {} | F1-Score: {}\".format(timestep, ts_f1))\n",
    "#     f1_scores.append(ts_f1)\n",
    "#     true_test.append(test_y)\n",
    "#     predictions_test.append(y_pred)\n",
    "        \n",
    "# f1_score_test = f1_score(np.concatenate(true_test, axis=0),   \n",
    "#                          np.concatenate(predictions_test, axis=0), \n",
    "#                          average='binary')\n",
    "# print(\"F1-Score on test set: {}\".format(round(f1_score_test, 3)))     \n",
    "\n",
    "# recall_score_test = recall_score(np.concatenate(true_test, axis=0),   \n",
    "#                                  np.concatenate(predictions_test, axis=0), \n",
    "#                                  average='binary')\n",
    "# print(\"Recall on test set: {}\".format(round(recall_score_test, 3)))      \n",
    "\n",
    "# precision_score_test = precision_score(np.concatenate(true_test, axis=0),   \n",
    "#                                        np.concatenate(predictions_test, axis=0), \n",
    "#                                        average='binary')\n",
    "# print(\"Precision on test set: {}\".format(round(precision_score_test, 3)))    \n",
    "\n",
    "# confusion_matrix_test = confusion_matrix(np.concatenate(true_test, axis=0), \n",
    "#                                          np.concatenate(predictions_test, axis=0))\n",
    "# print(\"Confusion_matrix: {}\".format(confusion_matrix_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # display(train_data)\n",
    "# # display(test_data)\n",
    "\n",
    "# # ncr_X, ncr_y = ncr.fit_resample(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "# # sm = SMOTE()\n",
    "# # X, y = sm.fit_resample(ncr_X, ncr_y)\n",
    "\n",
    "# # ncr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "# # ncr_X, ncr_y = ncr.fit_resample(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# model = xgb.XGBClassifier()\n",
    "# model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# # model.fit(train_data.iloc[:,:-1], train_data[\"class\"])\n",
    "\n",
    "# max_timestep = test_data[\"ts\"].max()\n",
    "# true_test = []\n",
    "# predictions_test = []\n",
    "# timestep_range = np.arange(35, max_timestep)\n",
    "\n",
    "# ensembles = []\n",
    "\n",
    "# for timestep in timestep_range:\n",
    "\n",
    "#     train = test_data[test_data[\"ts\"] == timestep]\n",
    "#     train_X = train.iloc[:,:-1]\n",
    "#     train_y = train[\"class\"]\n",
    "    \n",
    "#     if timestep == 35:\n",
    "#         y_pred = model.predict(train_X)\n",
    "#         ts_f1 = round(f1_score(train_y, y_pred, average='binary'), 3)     \n",
    "#         print(\"Timestep: {} | F1-Score: {}\".format(timestep, ts_f1))\n",
    "#         true_test.append(train_y)\n",
    "#         predictions_test.append(y_pred)\n",
    "     \n",
    "#     #ncr_X, ncr_y = ncr.fit_resample(train_X, train_y)\n",
    "#     booster = model.get_booster()\n",
    "#     model.fit(train_X, train_y, xgb_model=booster)\n",
    "       \n",
    "#     test = test_data[test_data[\"ts\"] == timestep + 1]\n",
    "#     test_X = test.iloc[:,:-1]\n",
    "#     test_y = test[\"class\"]\n",
    "    \n",
    "#     y_pred = model.predict(test_X)\n",
    "#     ts_f1 = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#     print(\"Timestep: {} | F1-Score: {}\".format(timestep + 1, ts_f1))\n",
    "#     true_test.append(test_y)\n",
    "#     predictions_test.append(y_pred)\n",
    "        \n",
    "#     tmp_model = xgb.XGBClassifier()\n",
    "#     tmp_model.fit(train_X, train_y)\n",
    "#     ensembles.append(tmp_model) \n",
    "    \n",
    "#     print(\"--------------------\")\n",
    "#     for i in range(len(ensembles) - 1):\n",
    "#         tmp = ensembles[i]\n",
    "#         tmp_booster = tmp.get_booster()\n",
    "#         tmp.fit(train_X, train_y, xgb_model=tmp_booster)\n",
    "#         ensembles[i] = tmp \n",
    "#         y_pred = tmp.predict(test_X)\n",
    "#         f1_tmp = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "#         print(f1_tmp)\n",
    "#     print(\"--------------------\")\n",
    "\n",
    "    \n",
    "# #     y_pred = tmp_model.predict(test_X)\n",
    "# #     ts_f1_tmp = round(f1_score(test_y, y_pred, average='binary'), 3)\n",
    "    \n",
    "# #     if ts_f1_tmp > ts_f1:\n",
    "# #         print(\"TMP_Timestep: {} | F1-Score: {}\".format(timestep + 1, ts_f1_tmp))\n",
    "\n",
    "    \n",
    "    \n",
    "# f1_score_test = f1_score(np.concatenate(true_test, axis=0),   \n",
    "#                          np.concatenate(predictions_test, axis=0), \n",
    "#                          average='binary')\n",
    "# print(\"F1-Score on test set: {}\".format(round(f1_score_test, 3)))     \n",
    "\n",
    "# recall_score_test = recall_score(np.concatenate(true_test, axis=0),   \n",
    "#                                  np.concatenate(predictions_test, axis=0), \n",
    "#                                  average='binary')\n",
    "# print(\"Recall on test set: {}\".format(round(recall_score_test, 3)))      \n",
    "\n",
    "# precision_score_test = precision_score(np.concatenate(true_test, axis=0),   \n",
    "#                                        np.concatenate(predictions_test, axis=0), \n",
    "#                                        average='binary')\n",
    "# print(\"Precision on test set: {}\".format(round(precision_score_test, 3)))    \n",
    "\n",
    "# confusion_matrix_test = confusion_matrix(np.concatenate(true_test, axis=0), \n",
    "#                                          np.concatenate(predictions_test, axis=0))\n",
    "# print(\"Confusion_matrix: {}\".format(confusion_matrix_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('btc-classifier': conda)",
   "language": "python",
   "name": "python37664bitbtcclassifiercondaf328939486114fc0aeb107830f867d66"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
