{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delinvas/anaconda3/envs/btc-classifier/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "import numpy as np\n",
    "import cryptoaml.datareader as cdr\n",
    "from collections import OrderedDict\n",
    "from cryptoaml.models import (RandomForestAlgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cdr.get_data(\"elliptic\")\n",
    "data_sets = data.train_test_split(train_size=0.7, feat_set=[\"LF\", \"AF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 50, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestAlgo(n_estimators=50, max_features=50)\n",
    "print(rf.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "total_runs = 100\n",
    "\n",
    "for feature_set in data_sets:\n",
    "    \n",
    "    # Get current feature set \n",
    "    tmp_dataset = data_sets[feature_set]\n",
    "    \n",
    "    # Training set \n",
    "    tmp_dataset_train_X = tmp_dataset.train_X\n",
    "    tmp_dataset_train_y = tmp_dataset.train_y\n",
    "    \n",
    "    # Test set \n",
    "    tmp_dataset_test_X = tmp_dataset.test_X\n",
    "    tmp_dataset_test_y = tmp_dataset.test_y\n",
    "    \n",
    "    metrics[feature_set] = {}\n",
    "    metrics[feature_set][\"precision\"] = []\n",
    "    metrics[feature_set][\"recall\"] = []\n",
    "    metrics[feature_set][\"f1\"] = []\n",
    "    metrics[feature_set][\"f1_micro\"] = []\n",
    "    \n",
    "    for i in range(total_runs):\n",
    "        rf.fit(tmp_dataset_train_X, tmp_dataset_train_y)\n",
    "        tmp_metrics = rf.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "                                  X_test=tmp_dataset_test_X,\n",
    "                                  y_test=tmp_dataset_test_y)\n",
    "        \n",
    "        metrics[feature_set][\"precision\"].append(tmp_metrics[\"precision\"])\n",
    "        metrics[feature_set][\"recall\"].append(tmp_metrics[\"recall\"])\n",
    "        metrics[feature_set][\"f1\"].append(tmp_metrics[\"f1\"])\n",
    "        metrics[feature_set][\"f1_micro\"].append(tmp_metrics[\"f1_micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "LF\n",
      "===========================================\n",
      "\t precision\n",
      "\t\tmean:0.856\n",
      "\t\tstd:0.011\n",
      "\t recall\n",
      "\t\tmean:0.698\n",
      "\t\tstd:0.009\n",
      "\t f1\n",
      "\t\tmean:0.769\n",
      "\t\tstd:0.006\n",
      "\t f1_micro\n",
      "\t\tmean:0.973\n",
      "\t\tstd:0.001\n",
      "===========================================\n",
      "AF\n",
      "===========================================\n",
      "\t precision\n",
      "\t\tmean:0.924\n",
      "\t\tstd:0.016\n",
      "\t recall\n",
      "\t\tmean:0.722\n",
      "\t\tstd:0.002\n",
      "\t f1\n",
      "\t\tmean:0.81\n",
      "\t\tstd:0.006\n",
      "\t f1_micro\n",
      "\t\tmean:0.978\n",
      "\t\tstd:0.001\n"
     ]
    }
   ],
   "source": [
    "for feature_set in metrics:\n",
    "    print(\"===========================================\")\n",
    "    print(feature_set)\n",
    "    print(\"===========================================\")\n",
    "\n",
    "    for metric in metrics[feature_set]:\n",
    "        metric_mean = round(np.mean(metrics[feature_set][metric]),3)\n",
    "        metric_std = round(np.std(metrics[feature_set][metric]),3)\n",
    "        print(\"\\t {}\\n\\t\\tmean:{}\\n\\t\\tstd:{}\".format(metric, metric_mean, metric_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btc-classifier] *",
   "language": "python",
   "name": "conda-env-btc-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
