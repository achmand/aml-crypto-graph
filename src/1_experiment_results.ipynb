{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "# Boosting Algorithms vs Random Forest using Elliptic Dataset\n",
    "<hr>\n",
    "\n",
    "### Table of Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### importing dependencies #############################################\n",
    "import matplotlib.pyplot as plt\n",
    "from cryptoaml.utils import read_pickle\n",
    "from IPython.core.display import display, HTML\n",
    "from cryptoaml.metrics import (\n",
    "    results_table, \n",
    "    plot_metric_dist,\n",
    "    plot_feature_imp,\n",
    "    print_model_params, \n",
    "    plot_result_matrices,\n",
    "    display_metrics_stats,\n",
    "    elliptic_time_indexed_results\n",
    ")\n",
    "\n",
    "###### constants ##########################################################\n",
    "N_features          = 15 # for feature importance N top/bottom\n",
    "EXP_RESULT_PATH     = \"persistence/experiment_1/results\"\n",
    "BENCHMARK_RESULTS   = \"{}/{}\".format(EXP_RESULT_PATH, \"benchmark_model_results.pkl\")\n",
    "DEFAULT_RESULTS     = \"{}/{}\".format(EXP_RESULT_PATH, \"defaults_models_results.pkl\")\n",
    "TUNED_RESULTS       = \"{}/{}\".format(EXP_RESULT_PATH, \"tuned_models_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model \n",
    "\n",
    "Experiment performed on the [elliptic dataset](https://www.kaggle.com/ellipticco/elliptic-data-set) [1,2]\n",
    "\n",
    "Models were tested on the following feature sets:\n",
    "- Local Features (LF)\n",
    "- Local Features and Node Embeddings extracted from GCN (LF_NE) \n",
    "- All Features - Aggregated Features and Local Features (AF)\n",
    "- All Features and Node Embeddings extracted from GCN (AF_NE) \n",
    "\n",
    "__Results obtained in the original paper [2]__\n",
    "\n",
    "<table style=\"border-collapse:collapse;border-spacing:0;border-color:#ccc\" class=\"tg\"><tr><th style=\"font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#f0f0f0;text-align:center;vertical-align:top\" rowspan=\"2\"><br><br>Method<br></th><th style=\"font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#f0f0f0;text-align:center;vertical-align:top\" colspan=\"3\">Illicit</th><th style=\"font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#f0f0f0;text-align:center;vertical-align:top\">MicroAVG</th></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#fff;font-weight:bold;text-align:center;vertical-align:top\">Precision</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#fff;font-weight:bold;text-align:center;vertical-align:top\">Recall</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#fff;font-weight:bold;text-align:center;vertical-align:top\">F1</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#333;background-color:#fff;font-weight:bold;text-align:center;vertical-align:top\">F1</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">LogReg <span style=\"font-style:italic\">(AF)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.404</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.593</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.481</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.931</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">LogReg <span style=\"font-style:italic\">(AF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.537</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.528</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.533</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:inherit;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.945</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">LogReg <span style=\"font-style:italic\">(LF)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.348</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.668</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.457</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.920</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">LogReg <span style=\"font-style:italic\">(LF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.518</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.571</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.543</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.945</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">RF <span style=\"font-style:italic\">(AF)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.956</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.670</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.788</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.977</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">RF <span style=\"font-style:italic\">(AF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">0.971</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#333333;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">0.675</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">0.796</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.978</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">RF <span style=\"font-style:italic\">(LF)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.803</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.611</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.694</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.966</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">RF <span style=\"font-style:italic\">(LF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.874</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.668</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.759</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.973</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">MLP (<span style=\"font-style:italic\">AF</span>)</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.694</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.617</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.653</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.962</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">MLP <span style=\"font-style:italic\">(AF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.780</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.617</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.689</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.967</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">MLP <span style=\"font-style:italic\">(LF)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.637</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.662</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.649</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.958</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">MLP <span style=\"font-style:italic\">(LF+NE)</span></td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.6819</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.5782</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.6258</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#34ff34;text-align:center;vertical-align:top\">0.986</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">GCN</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.812</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.512</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.628</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.961</td></tr><tr><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">Skip-GCN</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.812</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.623</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.705</td><td style=\"font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#000000;color:#000000;background-color:#fff;text-align:center;vertical-align:top\">0.966</td></tr></table>\n",
    "\n",
    "\n",
    "TODO -> ADD IMAGE OF TIME PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load results for benchmark model\n",
    "benchmark_model = \"random_forest\"\n",
    "benchmark_results = read_pickle(BENCHMARK_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics (Benchmark)\n",
    "- <i>Precision</i> \n",
    "- <i>Recall</i> \n",
    "- <i>F1</i>\n",
    "- <i>F1 Micro Avg/Accuracy<i/>\n",
    "- AUC\n",
    "    \n",
    "<small>\n",
    "    <i>\n",
    "    Italics text refers to metrics which were used in the benchmark paper. The results reproduce are very close to the ones documented in the benchmark paper [2], shown in the previous section. In our test run we managed to obtain higher results using the same parameters specified.\n",
    "    </i>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all the perfomance metrics\n",
    "print(\"Performance metrics for benchmark model\")\n",
    "benchmark_metrics_df = results_table(benchmark_results)\n",
    "display(benchmark_metrics_df)\n",
    "\n",
    "# sorted by f1 score\n",
    "print(\"Performance metrics for benchmark model sorted by f1-score\")\n",
    "display(benchmark_metrics_df.sort_values(\"f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Statistics (Benchmark)\n",
    "\n",
    "<i>Note: Since random forest is non-deterministic in nature, we ran the model for 100 iterations and averaged the results. This was done to insure robustness and was also recommended in previous studies.<i/>\n",
    "    \n",
    "Below we show statistics for the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display stats for each metric for benchmark model over 100 runs\n",
    "display_metrics_stats(benchmark_results)\n",
    "\n",
    "# plot f1 score distribution for benchmark model over 100 runs\n",
    "plot_metric_dist(benchmark_results, \"f1\", figsize=(17,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot confusion matrices for benchmark model \n",
    "plot_result_matrices(benchmark_results, figsize=(17,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Results over Test Time Span (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot f1 results over test time span, for benchmark model \n",
    "elliptic_time_indexed_results(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot top/bottom N features for benchmark model \n",
    "plot_feature_imp(benchmark_results, N_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters (Benchmark)\n",
    "\n",
    "Same parameters utilised on all feature sets.\n",
    "\n",
    "- n_estimators: 50\n",
    "- max_features: 50\n",
    "\n",
    "<small>\n",
    "    <i>\n",
    "    As described in the benchmark paper [2].\n",
    "    </i>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters used to train random_forest, all feature sets were trained,\n",
    "# on the same parameters\n",
    "print_model_params(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters - Boosting Models\n",
    "- [XGBoost: eXtreme Gradient Boosting](https://xgboost.readthedocs.io/en/latest/) \n",
    "- [LightGBM: Light Gradient Boosting Machine](https://lightgbm.readthedocs.io/en/latest/) \n",
    "- [CatBoost](https://catboost.ai/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results for default models\n",
    "default_results = read_pickle(DEFAULT_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics (Defaults)\n",
    "- <i>Precision</i> \n",
    "- <i>Recall</i> \n",
    "- <i>F1</i>\n",
    "- <i>F1 Micro Avg/Accuracy<i/>\n",
    "- AUC\n",
    "    \n",
    "<small>\n",
    "    <i>\n",
    "    Italics text refers to metrics which were used in the benchmark paper.\n",
    "    </i>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all the perfomance metrics\n",
    "print(\"Performance metrics for defaults boosting models\")\n",
    "defaults_metrics_df = results_table(default_results)\n",
    "display(defaults_metrics_df)\n",
    "\n",
    "# sorted by f1 score\n",
    "print(\"Performance metrics for defaults boosting models sorted by f1-score\")\n",
    "display(defaults_metrics_df.sort_values(\"f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices (Defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot confusion matrices for boosting models with default parameters \n",
    "plot_result_matrices(default_results, figsize=(17,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Results over Test Time Span (Defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot f1 results over test time span, \n",
    "# for boosting models with default parameters \n",
    "\n",
    "# in this plot we also display benchmark model\n",
    "tmp_results = {**benchmark_results, **default_results}\n",
    "elliptic_time_indexed_results(tmp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (Defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot top/bottom N features for boosting models with default parameters \n",
    "plot_feature_imp(default_results, N_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters (Defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print parameters used to train boosting algorithms with default params\n",
    "print_model_params(default_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Parameters - Boosting Models\n",
    "- [XGBoost: eXtreme Gradient Boosting](https://xgboost.readthedocs.io/en/latest/) \n",
    "- [LightGBM: Light Gradient Boosting Machine](https://lightgbm.readthedocs.io/en/latest/) \n",
    "- [CatBoost](https://catboost.ai/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results for tuned models\n",
    "tuned_results = read_pickle(TUNED_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics (Tuned)\n",
    "- <i>Precision</i> \n",
    "- <i>Recall</i> \n",
    "- <i>F1</i>\n",
    "- <i>F1 Micro Avg/Accuracy<i/>\n",
    "- AUC\n",
    "    \n",
    "<small>\n",
    "    <i>\n",
    "    Italics text refers to metrics which were used in the benchmark paper.\n",
    "    </i>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all the perfomance metrics\n",
    "print(\"Performance metrics for tuned boosting models\")\n",
    "tuned_metrics_df = results_table(tuned_results)\n",
    "display(tuned_metrics_df)\n",
    "\n",
    "# sorted by f1 score\n",
    "print(\"Performance metrics for tuned boosting models sorted by f1-score\")\n",
    "display(tuned_metrics_df.sort_values(\"f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot confusion matrices for boosting models with tuned parameters \n",
    "plot_result_matrices(tuned_results, figsize=(17,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Results over Test Time Span (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot f1 results over test time span, \n",
    "# for boosting models with default parameters \n",
    "\n",
    "# in this plot we also display benchmark model\n",
    "tmp_results = {**benchmark_results, **tuned_results}\n",
    "elliptic_time_indexed_results(tmp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot top/bottom N features for boosting models with tuned parameters \n",
    "plot_feature_imp(tuned_results, N_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Studies\n",
    "\n",
    "- Hyperparameters were tuned using stepwise tuning (100 iterations each step)\n",
    "- Both steps utilise the 70% train dataset\n",
    "- Cross validation applied during each iteration (Stratified Kfold and K=10)\n",
    "- First step we tune n_estimators and learning rate using RandomSearch \n",
    "- Then we train the other parameters using a Bayesian Optimization - Tree Parzen Estimator (TPE)\n",
    "\n",
    "Why stepwise tuning ?\n",
    "\n",
    "<i>“As described in Sections 2.1 and 2.2, a trade-off exists among maximum tree depth, learning rate and the number of iteration in GB and XGBoost, which violates the independence assumption in the TPE algorithm. Therefore, we introduce a stepwise training process. First, learning rate and the number of boosts are manually determined. We follow the default learning rate 0.1, which is also suggested value in GB (Friedman, 2001).“ </i>\n",
    "\n",
    "From: [A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring](https://www.sciencedirect.com/science/article/abs/pii/S0957417417301008)\n",
    "\n",
    "TODO: Discuss what to show here with supervisors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print parameters used to train boosting algorithms with tuned params\n",
    "print_model_params(tuned_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis \n",
    "TODO: Discuss with tutors here\n",
    "\n",
    "You may then correctly apply the paired Student’s t-test. This is most unlikely as we are often working with small data samples.\n",
    "\n",
    "McNemar’s test or 5×2 Cross-Validation\n",
    "\n",
    "Wilcoxon signed-rank test: This test has less statistical power than the paired t-test, although more power when the expectations of the t-test are violated, such as independence.\n",
    "\n",
    "\n",
    "Correct use of statistical tests is challenging, and there is some consensus for using the McNemar’s test or 5×2 cross-validation with a modified paired Student t-test.\n",
    "\n",
    "https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Elliptic, www.elliptic.co.\n",
    "\n",
    "[2] M. Weber, G. Domeniconi, J. Chen, D. K. I. Weidele, C. Bellei, T. Robinson, C. E. Leiserson, \"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\", KDD ’19 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btc-classifier] *",
   "language": "python",
   "name": "conda-env-btc-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
