{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delinvas/anaconda3/envs/btc-classifier/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "###### importing dependencies #############################################\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import cryptoaml.datareader as cdr\n",
    "from collections import OrderedDict\n",
    "from cryptoaml.metrics import results_table \n",
    "from cryptoaml.models import RandomForestAlgo, XgboostAlgo, LightGbmAlgo, CatBoostAlgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models without tuning \n",
    "elliptic = cdr.get_data(\"elliptic\")\n",
    "elliptic_sets = elliptic.train_test_split(train_size=0.7, \n",
    "                                          feat_set=[\"LF\", \"AF\"], \n",
    "                                          inc_meta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models with default parameters  \n",
    "models_default = OrderedDict()\n",
    "\n",
    "rf_default = RandomForestAlgo(n_jobs=-1, n_estimators=50, max_features=50)\n",
    "models_default[rf_default.model_name_] = rf_default\n",
    "\n",
    "# Using the default values for XGBoost Classifier will obtain reproducable results \n",
    "# => 'gblinear' booster with shotgun updater is nondeterministic as it uses Hogwild algorithm [Default='gbtree']\n",
    "# =>  parameters such as subsample and colsample_by_* are set to 1, meaning no random sampling will be used \n",
    "xgb_default = XgboostAlgo(n_jobs=-1)\n",
    "models_default[xgb_default.model_name_] = xgb_default\n",
    "\n",
    "light_default = LightGbmAlgo(n_jobs=-1)\n",
    "models_default[light_default.model_name_] = light_default\n",
    "\n",
    "cat_default = CatBoostAlgo(thread_count=-1, verbose=False)\n",
    "models_default[cat_default.model_name_] = cat_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################\n",
      "Elliptic Dataset - Feature Set [random_forest] \n",
      "######################################################\n",
      "- Training & Extracting Results - Feature Set [LF]\n",
      "OrderedDict([('precision', 0.8905882352941177),\n",
      "             ('recall', 0.6989843028624192),\n",
      "             ('f1', 0.7832384893947233),\n",
      "             ('f1_micro', 0.9748650269946011),\n",
      "             ('confusion', array([[15494,    93],\n",
      "       [  326,   757]]))])\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 50,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': -1,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "- Training & Extracting Results - Feature Set [AF]\n",
      "OrderedDict([('precision', 0.8966704936854191),\n",
      "             ('recall', 0.7211449676823638),\n",
      "             ('f1', 0.7993858751279427),\n",
      "             ('f1_micro', 0.9764847030593882),\n",
      "             ('confusion', array([[15497,    90],\n",
      "       [  302,   781]]))])\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 50,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': -1,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "\n",
      "######################################################\n",
      "Elliptic Dataset - Feature Set [xg_boost] \n",
      "######################################################\n",
      "- Training & Extracting Results - Feature Set [LF]\n",
      "OrderedDict([('precision', 0.8765859284890427),\n",
      "             ('recall', 0.7017543859649122),\n",
      "             ('f1', 0.7794871794871795),\n",
      "             ('f1_micro', 0.9742051589682064),\n",
      "             ('confusion', array([[15480,   107],\n",
      "       [  323,   760]]))])\n",
      "{'base_score': 0.5,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 1,\n",
      " 'gamma': 0,\n",
      " 'gpu_id': -1,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': 0.300000012,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 1,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': 0,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'scale_pos_weight': 1,\n",
      " 'subsample': 1,\n",
      " 'tree_method': None,\n",
      " 'validate_parameters': False,\n",
      " 'verbosity': None}\n",
      "- Training & Extracting Results - Feature Set [AF]\n",
      "OrderedDict([('precision', 0.902073732718894),\n",
      "             ('recall', 0.7229916897506925),\n",
      "             ('f1', 0.8026652998462326),\n",
      "             ('f1_micro', 0.9769046190761848),\n",
      "             ('confusion', array([[15502,    85],\n",
      "       [  300,   783]]))])\n",
      "{'base_score': 0.5,\n",
      " 'booster': None,\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 1,\n",
      " 'gamma': 0,\n",
      " 'gpu_id': -1,\n",
      " 'importance_type': 'gain',\n",
      " 'interaction_constraints': None,\n",
      " 'learning_rate': 0.300000012,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 1,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'binary:logistic',\n",
      " 'random_state': 0,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'scale_pos_weight': 1,\n",
      " 'subsample': 1,\n",
      " 'tree_method': None,\n",
      " 'validate_parameters': False,\n",
      " 'verbosity': None}\n",
      "\n",
      "######################################################\n",
      "Elliptic Dataset - Feature Set [light_boost] \n",
      "######################################################\n",
      "- Training & Extracting Results - Feature Set [LF]\n",
      "OrderedDict([('precision', 0.8612975391498882),\n",
      "             ('recall', 0.7109879963065558),\n",
      "             ('f1', 0.7789580171977744),\n",
      "             ('f1_micro', 0.9737852429514097),\n",
      "             ('confusion', array([[15463,   124],\n",
      "       [  313,   770]]))])\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 1.0,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': -1,\n",
      " 'min_child_samples': 20,\n",
      " 'min_child_weight': 0.001,\n",
      " 'min_split_gain': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'num_leaves': 31,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.0,\n",
      " 'reg_lambda': 0.0,\n",
      " 'silent': True,\n",
      " 'subsample': 1.0,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0}\n",
      "- Training & Extracting Results - Feature Set [AF]\n",
      "OrderedDict([('precision', 0.9310344827586207),\n",
      "             ('recall', 0.7229916897506925),\n",
      "             ('f1', 0.813929313929314),\n",
      "             ('f1_micro', 0.9785242951409718),\n",
      "             ('confusion', array([[15529,    58],\n",
      "       [  300,   783]]))])\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 1.0,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': -1,\n",
      " 'min_child_samples': 20,\n",
      " 'min_child_weight': 0.001,\n",
      " 'min_split_gain': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': -1,\n",
      " 'num_leaves': 31,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.0,\n",
      " 'reg_lambda': 0.0,\n",
      " 'silent': True,\n",
      " 'subsample': 1.0,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0}\n",
      "\n",
      "######################################################\n",
      "Elliptic Dataset - Feature Set [cat_boost] \n",
      "######################################################\n",
      "- Training & Extracting Results - Feature Set [LF]\n",
      "OrderedDict([('precision', 0.9015421115065243),\n",
      "             ('recall', 0.7017543859649122),\n",
      "             ('f1', 0.7892004153686397),\n",
      "             ('f1_micro', 0.9756448710257949),\n",
      "             ('confusion', array([[15504,    83],\n",
      "       [  323,   760]]))])\n",
      "{'approx_on_full_history': False,\n",
      " 'bayesian_matrix_reg': 0.1000000015,\n",
      " 'best_model_min_trees': 1,\n",
      " 'boost_from_average': False,\n",
      " 'boosting_type': 'Plain',\n",
      " 'bootstrap_type': 'MVS',\n",
      " 'border_count': 254,\n",
      " 'class_names': ['0', '1'],\n",
      " 'classes_count': 0,\n",
      " 'depth': 6,\n",
      " 'eval_metric': 'Logloss',\n",
      " 'feature_border_type': 'GreedyLogSum',\n",
      " 'fold_len_multiplier': 2,\n",
      " 'fold_permutation_block': 0,\n",
      " 'has_time': False,\n",
      " 'iterations': 1000,\n",
      " 'l2_leaf_reg': 3,\n",
      " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
      " 'leaf_estimation_iterations': 10,\n",
      " 'leaf_estimation_method': 'Newton',\n",
      " 'learning_rate': 0.04382399842,\n",
      " 'loss_function': 'Logloss',\n",
      " 'model_shrink_rate': 0,\n",
      " 'model_size_reg': 0.5,\n",
      " 'nan_mode': 'Min',\n",
      " 'permutation_count': 4,\n",
      " 'random_seed': 0,\n",
      " 'random_strength': 1,\n",
      " 'rsm': 1,\n",
      " 'sampling_frequency': 'PerTree',\n",
      " 'score_function': 'Cosine',\n",
      " 'sparse_features_conflict_fraction': 0,\n",
      " 'subsample': 0.8000000119,\n",
      " 'task_type': 'CPU',\n",
      " 'use_best_model': False}\n",
      "- Training & Extracting Results - Feature Set [AF]\n",
      "OrderedDict([('precision', 0.9533742331288344),\n",
      "             ('recall', 0.7174515235457064),\n",
      "             ('f1', 0.8187565858798735),\n",
      "             ('f1_micro', 0.9793641271745651),\n",
      "             ('confusion', array([[15549,    38],\n",
      "       [  306,   777]]))])\n",
      "{'approx_on_full_history': False,\n",
      " 'bayesian_matrix_reg': 0.1000000015,\n",
      " 'best_model_min_trees': 1,\n",
      " 'boost_from_average': False,\n",
      " 'boosting_type': 'Plain',\n",
      " 'bootstrap_type': 'MVS',\n",
      " 'border_count': 254,\n",
      " 'class_names': ['0', '1'],\n",
      " 'classes_count': 0,\n",
      " 'depth': 6,\n",
      " 'eval_metric': 'Logloss',\n",
      " 'feature_border_type': 'GreedyLogSum',\n",
      " 'fold_len_multiplier': 2,\n",
      " 'fold_permutation_block': 0,\n",
      " 'has_time': False,\n",
      " 'iterations': 1000,\n",
      " 'l2_leaf_reg': 3,\n",
      " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
      " 'leaf_estimation_iterations': 10,\n",
      " 'leaf_estimation_method': 'Newton',\n",
      " 'learning_rate': 0.04382399842,\n",
      " 'loss_function': 'Logloss',\n",
      " 'model_shrink_rate': 0,\n",
      " 'model_size_reg': 0.5,\n",
      " 'nan_mode': 'Min',\n",
      " 'permutation_count': 4,\n",
      " 'random_seed': 0,\n",
      " 'random_strength': 1,\n",
      " 'rsm': 1,\n",
      " 'sampling_frequency': 'PerTree',\n",
      " 'score_function': 'Cosine',\n",
      " 'sparse_features_conflict_fraction': 0,\n",
      " 'subsample': 0.8000000119,\n",
      " 'task_type': 'CPU',\n",
      " 'use_best_model': False}\n"
     ]
    }
   ],
   "source": [
    "# extract results for elliptic dataset on different feature sets\n",
    "\n",
    "results = OrderedDict()\n",
    "results[\"elliptic\"] = OrderedDict()\n",
    "metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\", \"confusion\"]\n",
    "\n",
    "#extracting dataset results \n",
    "for model_key, model in models_default.items():\n",
    "    print(\"\\n######################################################\")\n",
    "    print(\"Elliptic Dataset - Feature Set [{0}] \".format(model_key))\n",
    "    print(\"######################################################\")\n",
    "    results[\"elliptic\"][model_key] = OrderedDict()\n",
    "        \n",
    "    for feature_set, feature_set_data in elliptic_sets.items():\n",
    "        print(\"- Training & Extracting Results - Feature Set [{}]\".format(feature_set))\n",
    "\n",
    "        if feature_set not in results[\"elliptic\"][model_key]:\n",
    "            results[\"elliptic\"][model_key][feature_set] = OrderedDict()\n",
    "\n",
    "        # train model with default parameters\n",
    "        tmp_train_X = feature_set_data.train_X\n",
    "        tmp_train_y = feature_set_data.train_y \n",
    "        model.fit(tmp_train_X, tmp_train_y)\n",
    "\n",
    "        # extract results \n",
    "        tmp_test_X = feature_set_data.test_X\n",
    "        tmp_test_y = feature_set_data.test_y\n",
    "        tmp_result = model.evaluate(metrics=metrics,\n",
    "                                    X=tmp_test_X, \n",
    "                                    y=tmp_test_y)\n",
    "\n",
    "\n",
    "        print(pprint.pformat(tmp_result))\n",
    "        print(pprint.pformat(model.get_params()))\n",
    "        results[\"elliptic\"][model_key][feature_set] = tmp_result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF \n",
    "# 0.7801920161697827\n",
    "# 0.8146214099216711\n",
    "\n",
    "# 0.7828715365239295\n",
    "# 0.8103626943005181\n",
    "\n",
    "# XGBoost \n",
    "# 0.7794871794871795\n",
    "# 0.7794871794871795\n",
    "\n",
    "# 0.8026652998462326\n",
    "# 0.8026652998462326\n",
    "\n",
    "# Light \n",
    "# 0.7789580171977744\n",
    "# 0.7789580171977744\n",
    "\n",
    "# 0.813929313929314\n",
    "# 0.813929313929314\n",
    "\n",
    "# CAT \n",
    "# 0.7892004153686397\n",
    "# 0.7892004153686397\n",
    "# 0.7892004153686397\n",
    "\n",
    "# 0.8187565858798735\n",
    "# 0.8187565858798735\n",
    "# 0.8187565858798735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results \n",
    "# print(results)\n",
    "# models = [x[0] for x in results[\"elliptic\"][\"LF\"].items()]\n",
    "# f1_scores = [x[\"f1\"] for x in results[\"elliptic\"][\"LF\"].values()]\n",
    "\n",
    "# print(f1_scores)\n",
    "# ax = sns.barplot(x=models, y=f1_scores)\n",
    "# ax.set(ylim=(0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_scores = [x[\"f1\"] for x in results[\"elliptic\"][\"AF\"].values()]\n",
    "\n",
    "# print(f1_scores)\n",
    "# ax = sns.barplot(x=models, y=f1_scores)\n",
    "# ax.set(ylim=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = [x[\"confusion\"] for x in results[\"elliptic\"][\"AF\"].values()]\n",
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_plt(data, title):\n",
    "    ax = sns.heatmap(data, \n",
    "                     annot=True, \n",
    "                     cmap=\"Blues\",  \n",
    "                     fmt=\"g\")\n",
    "    ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest_LF</td>\n",
       "      <td>0.890588</td>\n",
       "      <td>0.698984</td>\n",
       "      <td>0.783238</td>\n",
       "      <td>0.974865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest_AF</td>\n",
       "      <td>0.896670</td>\n",
       "      <td>0.721145</td>\n",
       "      <td>0.799386</td>\n",
       "      <td>0.976485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xg_boost_LF</td>\n",
       "      <td>0.876586</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.779487</td>\n",
       "      <td>0.974205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xg_boost_AF</td>\n",
       "      <td>0.902074</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.802665</td>\n",
       "      <td>0.976905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>light_boost_LF</td>\n",
       "      <td>0.861298</td>\n",
       "      <td>0.710988</td>\n",
       "      <td>0.778958</td>\n",
       "      <td>0.973785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>light_boost_AF</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.813929</td>\n",
       "      <td>0.978524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat_boost_LF</td>\n",
       "      <td>0.901542</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.975645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat_boost_AF</td>\n",
       "      <td>0.953374</td>\n",
       "      <td>0.717452</td>\n",
       "      <td>0.818757</td>\n",
       "      <td>0.979364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  precision    recall        f1  f1_micro\n",
       "0  random_forest_LF   0.890588  0.698984  0.783238  0.974865\n",
       "1  random_forest_AF   0.896670  0.721145  0.799386  0.976485\n",
       "2       xg_boost_LF   0.876586  0.701754  0.779487  0.974205\n",
       "3       xg_boost_AF   0.902074  0.722992  0.802665  0.976905\n",
       "4    light_boost_LF   0.861298  0.710988  0.778958  0.973785\n",
       "5    light_boost_AF   0.931034  0.722992  0.813929  0.978524\n",
       "6      cat_boost_LF   0.901542  0.701754  0.789200  0.975645\n",
       "7      cat_boost_AF   0.953374  0.717452  0.818757  0.979364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat_boost_AF</td>\n",
       "      <td>0.953374</td>\n",
       "      <td>0.717452</td>\n",
       "      <td>0.818757</td>\n",
       "      <td>0.979364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>light_boost_AF</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.813929</td>\n",
       "      <td>0.978524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xg_boost_AF</td>\n",
       "      <td>0.902074</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.802665</td>\n",
       "      <td>0.976905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest_AF</td>\n",
       "      <td>0.896670</td>\n",
       "      <td>0.721145</td>\n",
       "      <td>0.799386</td>\n",
       "      <td>0.976485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat_boost_LF</td>\n",
       "      <td>0.901542</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>0.975645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest_LF</td>\n",
       "      <td>0.890588</td>\n",
       "      <td>0.698984</td>\n",
       "      <td>0.783238</td>\n",
       "      <td>0.974865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xg_boost_LF</td>\n",
       "      <td>0.876586</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.779487</td>\n",
       "      <td>0.974205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>light_boost_LF</td>\n",
       "      <td>0.861298</td>\n",
       "      <td>0.710988</td>\n",
       "      <td>0.778958</td>\n",
       "      <td>0.973785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  precision    recall        f1  f1_micro\n",
       "7      cat_boost_AF   0.953374  0.717452  0.818757  0.979364\n",
       "5    light_boost_AF   0.931034  0.722992  0.813929  0.978524\n",
       "3       xg_boost_AF   0.902074  0.722992  0.802665  0.976905\n",
       "1  random_forest_AF   0.896670  0.721145  0.799386  0.976485\n",
       "6      cat_boost_LF   0.901542  0.701754  0.789200  0.975645\n",
       "0  random_forest_LF   0.890588  0.698984  0.783238  0.974865\n",
       "2       xg_boost_LF   0.876586  0.701754  0.779487  0.974205\n",
       "4    light_boost_LF   0.861298  0.710988  0.778958  0.973785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a = confusion_plt(confusion_matrix[0], \"test\")\n",
    "# b = confusion_plt(confusion_matrix[0], \"test\")\n",
    "# c = confusion_plt(confusion_matrix[0], \"test\")\n",
    "# d = confusion_plt(confusion_matrix[0], \"test\")\n",
    "\n",
    "\n",
    "# ACCURARCY        = \"accuracy\"\n",
    "# F1_BINARY        = \"f1\"\n",
    "# F1_MICRO         = \"f1_micro\"\n",
    "# RECALL_BINARY    = \"recall\"\n",
    "# PRECISION_BINARY = \"precision\"\n",
    "\n",
    "# results_table_metrics = {ACCURARCY, F1_BINARY, F1_MICRO, RECALL_BINARY, PRECISION_BINARY}\n",
    "\n",
    "    \n",
    "results_tbl = results_table(results[\"elliptic\"])\n",
    "display(results_tbl)\n",
    "display(results_tbl.sort_values(\"f1\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(17,15))\n",
    "# fig.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "# i = 1\n",
    "# for x in confusion_matrix:\n",
    "#     ax = fig.add_subplot(2, 2, i)\n",
    "#     sns.set(font_scale=1.4) \n",
    "#     confusion_plt(x, \"test\")\n",
    "#     i = i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btc-classifier] *",
   "language": "python",
   "name": "conda-env-btc-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
