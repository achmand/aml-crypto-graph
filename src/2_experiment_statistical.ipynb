{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "from cryptoaml.utils import read_pickle\n",
    "from scipy.stats import friedmanchisquare\n",
    "from Orange.evaluation.scoring import compute_CD\n",
    "from Orange.evaluation.scoring import graph_ranks\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_test(data1, data2):\n",
    "    stat, p = wilcoxon(data1, data2)\n",
    "    print('Statistics=%.3f, p=%.20f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Same distribution (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different distribution (reject H0)')\n",
    "        \n",
    "def t_test(data1, data2):\n",
    "    value, pvalue = ttest_ind(data1, data2, equal_var=False)\n",
    "    print(value, pvalue)\n",
    "    if pvalue > 0.05:\n",
    "        print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
    "    else:\n",
    "        print('Samples are likely drawn from different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptic_benchmark_results = read_pickle(\"persistence/experiment_1/results/benchmark_model_results.pkl\")\n",
    "elliptic_tuned_results = read_pickle(\"persistence/experiment_1/results/tuned_models_iter_results.pkl\")\n",
    "smote_elliptic_tuned_results = read_pickle(\"persistence/experiment_2.2/results/tuned_models_results.pkl\")\n",
    "ncl_elliptic_benchmark_tuned_results = read_pickle(\"persistence/experiment_2/results/tuned_benchmark_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (Precision)\n",
      "Statistics=94.000, p=0.00000000000000006348\n",
      "Different distribution (reject H0)\n",
      "-------------------------------------------------\n",
      "Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (Precision)\n",
      "Statistics=132.000, p=0.00000000000000456211\n",
      "Different distribution (reject H0)\n",
      "-------------------------------------------------\n",
      "Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (F1)\n",
      "Statistics=9.000, p=0.00000000000000000511\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (Precision)\")\n",
    "rank_test(elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"precision\"], \n",
    "          smote_elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"precision\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (Precision)\")\n",
    "rank_test(elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"recall\"], \n",
    "          smote_elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"recall\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned SMOTE XGBoost_AF vs Tuned XGB_AF (F1)\")\n",
    "rank_test(elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"f1\"], \n",
    "          smote_elliptic_tuned_results[\"xg_boost\"][\"AF\"][\"metrics_iterations\"][\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (Precision)\n",
      "Statistics=252.000, p=0.00000000000000548194\n",
      "Different distribution (reject H0)\n",
      "-------------------------------------------------\n",
      "Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (Recall)\n",
      "Statistics=344.500, p=0.00000000005135175113\n",
      "Different distribution (reject H0)\n",
      "-------------------------------------------------\n",
      "Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (F1)\n",
      "Statistics=64.000, p=0.00000000000000002634\n",
      "Different distribution (reject H0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (Precision)\")\n",
    "rank_test(elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"precision\"], \n",
    "          smote_elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"precision\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (Recall)\")\n",
    "rank_test(elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"recall\"], \n",
    "          smote_elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"recall\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned SMOTE LGBM_AF vs Tuned LGBM_AF (F1)\")\n",
    "rank_test(elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"f1\"], \n",
    "          smote_elliptic_tuned_results[\"light_boost\"][\"AF\"][\"metrics_iterations\"][\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned NCL RF_AF vs RF_AF (Precision)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ncl_elliptic_tuned_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0cfe0e90c00c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tuned NCL RF_AF vs RF_AF (Precision)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m rank_test(elliptic_benchmark_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"precision\"], \n\u001b[0;32m----> 3\u001b[0;31m           ncl_elliptic_tuned_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"precision\"])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tuned NCL RF_AF vs RF_AF (Recall)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ncl_elliptic_tuned_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Tuned NCL RF_AF vs RF_AF (Precision)\")\n",
    "rank_test(elliptic_benchmark_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"precision\"], \n",
    "          ncl_elliptic_benchmark_tuned_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"precision\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned NCL RF_AF vs RF_AF (Recall)\")\n",
    "rank_test(elliptic_benchmark_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"recall\"], \n",
    "          v[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"recall\"])\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Tuned NCL RF_AF vs RF_AF (f1)\")\n",
    "rank_test(elliptic_benchmark_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"f1\"], \n",
    "          ncl_elliptic_tuned_results[\"random_forest\"][\"AF\"][\"metrics_iterations\"][\"f1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btc-classifier] *",
   "language": "python",
   "name": "conda-env-btc-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
