{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delinvas/anaconda3/envs/btc-classifier/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Experiment 1 \n",
    "##########################################################################\n",
    "#\n",
    "# Hypothesis: 'Wheter boosting algorithms can improve on \n",
    "#              the results obtained by the benchmark model'\n",
    "#\n",
    "# Dataset: Elliptic dataset (BTC Transaction Graph) [Classification]\n",
    "#\n",
    "# Benchmark model: RandomForest '(Anti-Money Laundering in Bitcoin: Experimenting \n",
    "#                                with Graph Convolutional Networks for Financial Forensics)'\n",
    "#\n",
    "# Models: AdaBoost, LogitBoost, GradientBoosting, XGBoost, LightGBM, CatBoost\n",
    "#\n",
    "# Author: Dylan Vassallo <dylan.vassallo.18@um.edu.mt>\n",
    "\n",
    "# Importing dependencies\n",
    "import cryptoaml.datareader as cdr\n",
    "from collections import OrderedDict\n",
    "from cryptoaml.models import (RandomForestAlgo, \n",
    "                              AdaBoostAlgo, \n",
    "                              LogitBoostAlgo,\n",
    "                              GradientBoostAlgo, \n",
    "                              XgbBoostAlgo, \n",
    "                              LightGbmAlgo, \n",
    "                              CatBoostAlgo)\n",
    "\n",
    "# # Suppress deprecation warning due to numpy\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the Elliptic Dataset\n",
    "data = cdr.get_data(\"elliptic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LF_0</th>\n",
       "      <th>LF_1</th>\n",
       "      <th>LF_2</th>\n",
       "      <th>LF_3</th>\n",
       "      <th>LF_4</th>\n",
       "      <th>LF_5</th>\n",
       "      <th>LF_6</th>\n",
       "      <th>LF_7</th>\n",
       "      <th>LF_8</th>\n",
       "      <th>LF_9</th>\n",
       "      <th>...</th>\n",
       "      <th>LF_83</th>\n",
       "      <th>LF_84</th>\n",
       "      <th>LF_85</th>\n",
       "      <th>LF_86</th>\n",
       "      <th>LF_87</th>\n",
       "      <th>LF_88</th>\n",
       "      <th>LF_89</th>\n",
       "      <th>LF_90</th>\n",
       "      <th>LF_91</th>\n",
       "      <th>LF_92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139873</th>\n",
       "      <td>-0.172796</td>\n",
       "      <td>-0.120022</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.12197</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163452</td>\n",
       "      <td>-0.169269</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255168</td>\n",
       "      <td>-0.259251</td>\n",
       "      <td>-0.187191</td>\n",
       "      <td>-0.185274</td>\n",
       "      <td>-0.293715</td>\n",
       "      <td>-0.761914</td>\n",
       "      <td>-0.694235</td>\n",
       "      <td>-0.720879</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.025217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139891</th>\n",
       "      <td>-0.054145</td>\n",
       "      <td>-0.105252</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.12197</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.042054</td>\n",
       "      <td>-0.049573</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255168</td>\n",
       "      <td>-0.259251</td>\n",
       "      <td>-0.187191</td>\n",
       "      <td>-0.185274</td>\n",
       "      <td>-0.293583</td>\n",
       "      <td>-0.761719</td>\n",
       "      <td>-0.694058</td>\n",
       "      <td>-0.720663</td>\n",
       "      <td>1.135523</td>\n",
       "      <td>1.135279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139888</th>\n",
       "      <td>-0.111095</td>\n",
       "      <td>-0.064302</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.12197</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.100322</td>\n",
       "      <td>-0.107024</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255168</td>\n",
       "      <td>-0.259251</td>\n",
       "      <td>-0.187191</td>\n",
       "      <td>-0.185274</td>\n",
       "      <td>-0.293755</td>\n",
       "      <td>-0.760384</td>\n",
       "      <td>-0.692367</td>\n",
       "      <td>-0.719528</td>\n",
       "      <td>-1.084907</td>\n",
       "      <td>-1.084845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139883</th>\n",
       "      <td>0.504442</td>\n",
       "      <td>0.100068</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>-0.12197</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.529467</td>\n",
       "      <td>0.513939</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126695</td>\n",
       "      <td>0.119269</td>\n",
       "      <td>1.125590</td>\n",
       "      <td>1.128038</td>\n",
       "      <td>-0.225881</td>\n",
       "      <td>2.477036</td>\n",
       "      <td>3.192680</td>\n",
       "      <td>2.190127</td>\n",
       "      <td>1.135523</td>\n",
       "      <td>1.135279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139882</th>\n",
       "      <td>-0.171828</td>\n",
       "      <td>-0.133534</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.12197</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162463</td>\n",
       "      <td>-0.168294</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255168</td>\n",
       "      <td>-0.259251</td>\n",
       "      <td>-0.187191</td>\n",
       "      <td>-0.185274</td>\n",
       "      <td>-0.293557</td>\n",
       "      <td>-0.761856</td>\n",
       "      <td>-0.694235</td>\n",
       "      <td>-0.720776</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.025217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LF_0      LF_1      LF_2     LF_3      LF_4      LF_5      LF_6  \\\n",
       "139873 -0.172796 -0.120022  1.018602 -0.12197 -0.063725 -0.113002 -0.061584   \n",
       "139891 -0.054145 -0.105252  0.463609 -0.12197 -0.043875 -0.113002 -0.061584   \n",
       "139888 -0.111095 -0.064302 -0.091383 -0.12197 -0.043875 -0.113002 -0.061584   \n",
       "139883  0.504442  0.100068 -0.646376 -0.12197 -0.043875 -0.113002 -0.061584   \n",
       "139882 -0.171828 -0.133534  1.018602 -0.12197 -0.063725 -0.113002 -0.061584   \n",
       "\n",
       "            LF_7      LF_8      LF_9  ...     LF_83     LF_84     LF_85  \\\n",
       "139873 -0.163452 -0.169269 -0.049707  ... -0.255168 -0.259251 -0.187191   \n",
       "139891 -0.042054 -0.049573 -0.049707  ... -0.255168 -0.259251 -0.187191   \n",
       "139888 -0.100322 -0.107024 -0.049707  ... -0.255168 -0.259251 -0.187191   \n",
       "139883  0.529467  0.513939 -0.049707  ...  0.126695  0.119269  1.125590   \n",
       "139882 -0.162463 -0.168294 -0.049707  ... -0.255168 -0.259251 -0.187191   \n",
       "\n",
       "           LF_86     LF_87     LF_88     LF_89     LF_90     LF_91     LF_92  \n",
       "139873 -0.185274 -0.293715 -0.761914 -0.694235 -0.720879  0.025308  0.025217  \n",
       "139891 -0.185274 -0.293583 -0.761719 -0.694058 -0.720663  1.135523  1.135279  \n",
       "139888 -0.185274 -0.293755 -0.760384 -0.692367 -0.719528 -1.084907 -1.084845  \n",
       "139883  1.128038 -0.225881  2.477036  3.192680  2.190127  1.135523  1.135279  \n",
       "139882 -0.185274 -0.293557 -0.761856 -0.694235 -0.720776  0.025308  0.025217  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get different feature sets collection\n",
    "data_sets = data.train_test_split(train_size=0.7, feat_set=[\"LF\", \"AF\"], inc_meta=False)\n",
    "display(data_sets[\"LF\"].test_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 50, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Testing benchmark model \n",
    "rf = RandomForestAlgo(n_estimators=50, max_features=50)\n",
    "print(rf.params)\n",
    "\n",
    "# for feature_set in data_sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a collection of models which will be tested \n",
    "# models = OrderedDict()\n",
    "\n",
    "# # XGBoost \n",
    "# xgboost = XgbBoostAlgo()\n",
    "# models[\"xgboost\"] = xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter configuration (random_search)\n",
    "\n",
    "# # Xgboost parameter grid \n",
    "# xgboost_tune = {\n",
    "#     \"name\": \"random_grid\",\n",
    "#     \"cv\": 5,\n",
    "#     \"n_iter\": 2,\n",
    "#     \"param_grid\" :{\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "#                    \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "#                    \"max_depth\": [2, 4, 7, 10],\n",
    "#                    \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "#                    \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "#                    \"reg_alpha\": [0, 0.5, 1],\n",
    "#                    \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "#                    \"min_child_weight\": [1, 3, 5, 7],\n",
    "#                    \"n_estimators\": [100, 250, 500, 1000]}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start training models on different feature sets \n",
    "\n",
    "# # Loop all feature sets \n",
    "# for feature_set in data_sets:\n",
    "    \n",
    "#     # Get current feature set \n",
    "#     tmp_dataset = data_sets[feature_set]\n",
    "    \n",
    "#     # Training set \n",
    "#     tmp_dataset_train_X = tmp_dataset.train_X\n",
    "#     tmp_dataset_train_y = tmp_dataset.train_y\n",
    "    \n",
    "#     # Test set \n",
    "#     tmp_dataset_test_X = tmp_dataset.test_X\n",
    "#     tmp_dataset_test_y = tmp_dataset.train_y\n",
    "\n",
    "#     # Train/Tune/Test all models \n",
    "#     for model in models:\n",
    "        \n",
    "#         tmp_model = models[model]\n",
    "        \n",
    "#         print(model)\n",
    "#         print(feature_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # random_grid_tune = {\n",
    "# #     \"name\": \"random_grid\",\n",
    "# #     \"cv\": 5,\n",
    "# #     \"n_iter\": 2,\n",
    "# #     \"param_grid\" :{\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "# #                    \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "# #                    \"max_depth\": [2, 4, 7, 10],\n",
    "# #                    \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "# #                    \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "# #                    \"reg_alpha\": [0, 0.5, 1],\n",
    "# #                    \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "# #                    \"min_child_weight\": [1, 3, 5, 7],\n",
    "# #                    \"n_estimators\": [100, 250, 500, 1000]}\n",
    "# # }\n",
    "\n",
    "# xgboost = XgbBoostAlgo()\n",
    "# # xgboost.fit(af_datasplit.train_X, af_datasplit.train_y, tune=random_grid_tune)\n",
    "\n",
    "# xgboost.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(xgboost.params)\n",
    "# metrics = xgboost.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(xgboost.feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM = LightGbmAlgo()\n",
    "\n",
    "# lightGBM.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(lightGBM.params)\n",
    "# metrics = lightGBM.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(lightGBM.feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaBoost = AdaBoostAlgo()\n",
    "\n",
    "# adaBoost.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(adaBoost.params)\n",
    "# metrics = adaBoost.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(adaBoost.feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# catBoost = CatBoostAlgo(verbose=0)\n",
    "\n",
    "# catBoost.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(catBoost.params)\n",
    "# metrics = catBoost.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(catBoost.feature_importance.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gboost = GradientBoostAlgo()\n",
    "\n",
    "# gboost.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(gboost.params)\n",
    "# metrics = gboost.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(gboost.feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logitBoost = LogitBoostAlgo()\n",
    "\n",
    "# logitBoost.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# print(logitBoost.params)\n",
    "# metrics = logitBoost.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)\n",
    "# print(metrics)\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# display(logitBoost.feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# xgboost.save(\"saved_models/experiment_1/xgboost_elliptic_af\")\n",
    "\n",
    "\n",
    "# xgboost_load = XgbBoostAlgo()\n",
    "# xgboost_load.load(\"saved_models/experiment_1/xgboost_elliptic_af\")\n",
    "# print(xgboost_load.params)\n",
    "# metrics = xgboost_load.evaluate(metrics=[\"precision\", \"recall\", \"f1\", \"f1_micro\"], \n",
    "#                            X_test=af_datasplit.test_X, \n",
    "#                            y_test=af_datasplit.test_y)    \n",
    "# print(metrics)\n",
    "# display(xgboost_load.feature_importance.head())\n",
    "\n",
    "# y_pred = xgboost.predict(af_datasplit.test_X)\n",
    "# print(f1_score(af_datasplit.test_y, y_pred, average=\"binary\"))\n",
    "\n",
    "\n",
    "# # ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing dependencies\n",
    "# import cryptoaml.datareader as cdr\n",
    "# from collections import OrderedDict\n",
    "# from cryptoaml.models import XgbBoostAlgo, LightGbmAlgo\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new instance of Elliptic Dataset\n",
    "# ell = cdr.get_data(\"elliptic\", \n",
    "#                    encode_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgbAlgo = XgbBoostAlgo() \n",
    "# # print(xgbAlgo.params)\n",
    "\n",
    "# # lgb = LightGbmAlgo() \n",
    "# # print(lgb.params)\n",
    "# af_datasplit = ell.get_data_split(train_perc=0.7, input_feats=\"AF\", inc_unknown=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grid_param = {\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "#  \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "#  \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "#  \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "#  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "# classifier = xgb.XGBClassifier()\n",
    "# gd_sr = RandomizedSearchCV(estimator=classifier,\n",
    "#                            param_distributions=grid_param,\n",
    "#                            scoring=\"f1\",\n",
    "#                            n_iter = 10, \n",
    "#                            cv=5,\n",
    "#                            n_jobs=-1)\n",
    "\n",
    "# gd_sr.fit(af_datasplit.train_X, af_datasplit.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters = gd_sr.best_params_\n",
    "# print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = gd_sr.best_estimator_\n",
    "# print(best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = best_model.predict(af_datasplit.test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# print(f1_score(af_datasplit.test_y, y_pred, average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# classifier_2 = RandomForestClassifier(n_estimators=50, max_features=50)\n",
    "# classifier_2.fit(af_datasplit.train_X, af_datasplit.train_y)\n",
    "# y_pred_2 = classifier_2.predict(af_datasplit.test_X)\n",
    "# print(f1_score(af_datasplit.test_y, y_pred_2, average=\"binary\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:btc-classifier] *",
   "language": "python",
   "name": "conda-env-btc-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
