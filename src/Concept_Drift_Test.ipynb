{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/delinvas/anaconda3/envs/btc-classifier/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
      "\n",
      "The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cryptoaml.datareader as cdr\n",
    "from cryptoaml.models import RandomForestAlgo\n",
    "from skmultiflow.meta.adaptive_random_forests import AdaptiveRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptic = cdr.get_data(\"elliptic\")\n",
    "data = elliptic.train_test_split(train_size=0.7, \n",
    "                                 feat_set=\"AF\", \n",
    "                                 inc_meta=False,\n",
    "                                 inc_unknown=False)\n",
    "\n",
    "train_X = data.train_X\n",
    "train_y = data.train_y\n",
    "test_X = data.test_X\n",
    "test_y = data.test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestAlgo()\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_indexed_score(model, metric, X, y):\n",
    "    results = []\n",
    "    tmp_data = X.copy()\n",
    "    tmp_data[\"label\"] = y.copy()\n",
    "    ts_data = tmp_data.groupby(\"ts\")\n",
    "    for ts, group in ts_data:\n",
    "        test_ts_X = group.iloc[:,:-1]\n",
    "        test_ts_y = group[\"label\"]\n",
    "        evaluation = model.evaluate([metric], test_ts_X, test_ts_y)\n",
    "        label_count = group[\"label\"].value_counts()\n",
    "        results.append({\"timestep\": ts, \"score\":evaluation[metric], \"total_pos_label\": label_count.tolist()[1]}) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = time_indexed_score(rf, \"recall\", test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestep': 35, 'score': 0.967032967032967, 'total_pos_label': 182}, {'timestep': 36, 'score': 1.0, 'total_pos_label': 33}, {'timestep': 37, 'score': 0.625, 'total_pos_label': 40}, {'timestep': 38, 'score': 0.9009009009009009, 'total_pos_label': 111}, {'timestep': 39, 'score': 0.9259259259259259, 'total_pos_label': 81}, {'timestep': 40, 'score': 0.6339285714285714, 'total_pos_label': 112}, {'timestep': 41, 'score': 0.9310344827586207, 'total_pos_label': 116}, {'timestep': 42, 'score': 0.7949790794979079, 'total_pos_label': 239}, {'timestep': 43, 'score': 0.0, 'total_pos_label': 24}, {'timestep': 44, 'score': 0.041666666666666664, 'total_pos_label': 24}, {'timestep': 45, 'score': 0.0, 'total_pos_label': 5}, {'timestep': 46, 'score': 0.5, 'total_pos_label': 2}, {'timestep': 47, 'score': 0.0, 'total_pos_label': 22}, {'timestep': 48, 'score': 0.0, 'total_pos_label': 36}, {'timestep': 49, 'score': 0.017857142857142856, 'total_pos_label': 56}]\n"
     ]
    }
   ],
   "source": [
    "print(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TS:1\n",
      "Training TS:2\n",
      "Training TS:3\n",
      "Training TS:4\n",
      "Training TS:5\n",
      "Training TS:6\n",
      "Training TS:7\n",
      "Training TS:8\n",
      "Training TS:9\n",
      "Training TS:10\n",
      "Training TS:11\n",
      "Training TS:12\n",
      "Training TS:13\n",
      "Training TS:14\n",
      "Training TS:15\n",
      "Training TS:16\n",
      "Training TS:17\n",
      "Training TS:18\n",
      "Training TS:19\n",
      "Training TS:20\n",
      "Training TS:21\n",
      "Training TS:22\n",
      "Training TS:23\n",
      "Training TS:24\n",
      "Training TS:25\n",
      "Training TS:26\n",
      "Training TS:27\n",
      "Training TS:28\n",
      "Training TS:29\n",
      "Training TS:30\n",
      "Training TS:31\n",
      "Training TS:32\n",
      "Training TS:33\n",
      "Training TS:34\n"
     ]
    }
   ],
   "source": [
    "adaptive_rf = AdaptiveRandomForest(performance_metric=\"kappa\")\n",
    "\n",
    "tmp_data = train_X.copy()\n",
    "tmp_data[\"label\"] = train_y.copy()\n",
    "ts_data = tmp_data.groupby(\"ts\")\n",
    "for ts, group in ts_data:\n",
    "    print(\"Training TS:{}\".format(ts))\n",
    "    test_ts_X = group.iloc[:,:-1]\n",
    "    test_ts_y = group[\"label\"]\n",
    "    adaptive_rf = adaptive_rf.partial_fit(test_ts_X.values, test_ts_y.values, classes=np.array([0,1]))\n",
    "\n",
    "# learner.fit(train_X.values, train_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1152    7]\n",
      " [   6  176]]\n",
      "TS: 35, Score: 0.9643835616438357\n",
      "TS: 36, Score: 1.0\n",
      "TS: 37, Score: 0.8235294117647058\n",
      "TS: 38, Score: 0.8942307692307693\n",
      "TS: 39, Score: 0.9102564102564102\n",
      "TS: 40, Score: 0.7177033492822966\n",
      "TS: 41, Score: 0.9166666666666667\n",
      "TS: 42, Score: 0.8439560439560441\n",
      "TS: 43, Score: 0.17391304347826086\n",
      "TS: 44, Score: 0.1846153846153846\n",
      "TS: 45, Score: 0.0\n",
      "TS: 46, Score: 0.5\n",
      "TS: 47, Score: 0.11764705882352942\n",
      "TS: 48, Score: 0.38235294117647056\n",
      "TS: 49, Score: 0.875\n",
      "[[15406   181]\n",
      " [  230   853]]\n",
      "0.8058573452999529\n",
      "0.7876269621421976\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "# start= False\n",
    "# tmp_data = train_X.copy()\n",
    "# tmp_data[\"label\"] = train_y.copy()\n",
    "# ts_data = tmp_data.groupby(\"ts\")\n",
    "# for ts, group in ts_data:\n",
    "    \n",
    "#     booster = None \n",
    "#     if start == True:\n",
    "#         start = True \n",
    "#         booster = model.get_booster()\n",
    "        \n",
    "#     print(\"Training TS:{}\".format(ts))\n",
    "#     test_ts_X = group.iloc[:,:-1]\n",
    "#     test_ts_y = group[\"label\"]\n",
    "#     model.fit(train_set_X, train_set_y, xgb_model=booster)\n",
    "    \n",
    "    #adaptive_rf = adaptive_rf.partial_fit(test_ts_X.values, test_ts_y.values, classes=np.array([0,1]))\n",
    "\n",
    "all_x = 0 \n",
    "tmp_data = test_X.copy()\n",
    "predictions = []\n",
    "tmp_data[\"label\"] = test_y.copy()\n",
    "matrix_all = np.array([[0,0],[0,0]])\n",
    "\n",
    "for ts in np.arange(test_X[\"ts\"].min(), test_X[\"ts\"].max()):\n",
    "    train_set = tmp_data[tmp_data[\"ts\"] == ts]\n",
    "    train_set_X = train_set.iloc[:,:-1]\n",
    "    train_set_y = train_set[\"label\"]   \n",
    "    \n",
    "    \n",
    "#     X, y = ncr.fit_resample(train_set_X, train_set_y)\n",
    "    \n",
    "    test_set = tmp_data[tmp_data[\"ts\"] == ts + 1]\n",
    "    test_set_X = test_set.iloc[:,:-1]\n",
    "    test_set_y = test_set[\"label\"]\n",
    "    \n",
    "    if ts == 35:\n",
    "        y_pred = model.predict(train_set_X)\n",
    "        predictions.append(y_pred)\n",
    "        evaluation = f1_score(train_set_y, y_pred, average='binary')\n",
    "        matrix = confusion_matrix(train_set_y, y_pred)\n",
    "        matrix_all = matrix_all + matrix\n",
    "        \n",
    "        print(matrix)\n",
    "        \n",
    "        all_x += evaluation\n",
    "        print(\"TS: {}, Score: {}\".format(ts , evaluation)) \n",
    "    \n",
    "    booster = model.get_booster()\n",
    "    model.fit(train_set_X, train_set_y, xgb_model=booster)\n",
    "    y_pred = model.predict(test_set_X)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "#     adaptive_rf = adaptive_rf.partial_fit(train_set_X, train_set_y, classes=np.array([0,1]))\n",
    "#     y_pred = adaptive_rf.predict(test_set_X)\n",
    "\n",
    "    \n",
    "    all_x += evaluation\n",
    "    evaluation = f1_score(test_set_y, y_pred, average='binary')\n",
    "    matrix = confusion_matrix(test_set_y, y_pred)\n",
    "    matrix_all = matrix_all + matrix\n",
    "    print(\"TS: {}, Score: {}\".format(ts + 1 , evaluation))\n",
    "\n",
    "\n",
    "print(matrix_all)\n",
    "print(f1_score(test_y.values, np.concatenate(predictions, axis=0 ), average='binary'))\n",
    "print(recall_score(test_y.values, np.concatenate(predictions, axis=0 ), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8058573452999529\n",
    "# 0.7876269621421976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TS:1\n",
      "Training TS:2\n",
      "Training TS:3\n",
      "Training TS:4\n",
      "Training TS:5\n",
      "Training TS:6\n",
      "Training TS:7\n",
      "Training TS:8\n",
      "Training TS:9\n",
      "Training TS:10\n",
      "Training TS:11\n",
      "Training TS:12\n",
      "Training TS:13\n",
      "Training TS:14\n",
      "Training TS:15\n",
      "Training TS:16\n",
      "Training TS:17\n",
      "Training TS:18\n",
      "Training TS:19\n",
      "Training TS:20\n",
      "Training TS:21\n",
      "Training TS:22\n",
      "Training TS:23\n",
      "Training TS:24\n",
      "Training TS:25\n",
      "Training TS:26\n",
      "Training TS:27\n",
      "Training TS:28\n",
      "Training TS:29\n",
      "Training TS:30\n",
      "Training TS:31\n",
      "Training TS:32\n",
      "Training TS:33\n",
      "Training TS:34\n"
     ]
    }
   ],
   "source": [
    "from skmultiflow.meta import LearnNSE\n",
    "learn_nse = LearnNSE(base_estimator=xgb.XGBClassifier(), n_estimators=10, pruning=\"error\")\n",
    "\n",
    "tmp_data = train_X.copy()\n",
    "tmp_data[\"label\"] = train_y.copy()\n",
    "ts_data = tmp_data.groupby(\"ts\")\n",
    "for ts, group in ts_data:\n",
    "    \n",
    "#     if ts == 1: \n",
    "#         model = xgb.XGBClassifier()\n",
    "#         model.fit(test_ts_X.values, test_ts_y.values)\n",
    "#         learn_nse = OnlineBoosting(base_estimator=model)\n",
    "#         continue \n",
    "    \n",
    "    print(\"Training TS:{}\".format(ts))\n",
    "    test_ts_X = group.iloc[:,:-1]\n",
    "    test_ts_y = group[\"label\"]\n",
    "    \n",
    "    window_size = int(test_ts_X.shape[0]) \n",
    "    learn_nse.set_params(window_size=window_size)\n",
    "    learn_nse = learn_nse.partial_fit(test_ts_X.values, test_ts_y.values, classes=np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS 36: 0.0\n",
      "TS 37: 0.0\n",
      "TS 38: 0.0\n",
      "TS 39: 0.0\n",
      "TS 40: 0.0\n",
      "TS 41: 0.0\n",
      "TS 42: 0.0\n",
      "TS 43: 0.0\n",
      "TS 44: 0.0\n",
      "TS 45: 0.0\n",
      "TS 46: 0.0\n",
      "TS 47: 0.0\n",
      "TS 48: 0.0\n",
      "TS 49: 0.0\n"
     ]
    }
   ],
   "source": [
    "tmp_data = test_X.copy()\n",
    "tmp_data[\"label\"] = test_y.copy()\n",
    "matrix_all = np.array([[0,0],[0,0]])\n",
    "for ts in np.arange(test_X[\"ts\"].min(), test_X[\"ts\"].max()):\n",
    "    train_set = tmp_data[tmp_data[\"ts\"] == ts]\n",
    "    train_set_X = train_set.iloc[:,:-1]\n",
    "    train_set_y = train_set[\"label\"]      \n",
    "\n",
    "    test_set = tmp_data[tmp_data[\"ts\"] == ts + 1]\n",
    "    test_set_X = test_set.iloc[:,:-1].values\n",
    "    test_set_y = test_set[\"label\"].values\n",
    "    \n",
    "    window_size = int(train_set_X.shape[0]) \n",
    "    learn_nse.set_params(window_size=window_size)\n",
    "    learn_nse = learn_nse.partial_fit(train_set_X.values, train_set_y.values, classes=np.array([0,1]))\n",
    "    \n",
    "    y_pred = learn_nse.predict(test_set_X)\n",
    "    evaluation = f1_score(test_set_y, y_pred, average='binary')\n",
    "    print(\"TS {}: {}\".format(ts+1, evaluation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('btc-classifier': conda)",
   "language": "python",
   "name": "python37664bitbtcclassifiercondaf328939486114fc0aeb107830f867d66"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
